from fastapi import FastAPI, UploadFile, File, Form
from typing import List, Dict, Any
from pydantic import BaseModel
import asyncio
from datetime import datetime
from app.agents.dispatch_adapter import dispatch_help
from app.services.db_service import list_incidents, add_lost_found, list_lost_found, add_incident
import numpy as np
import cv2
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
from app.routes.camera import router as camera_router
import os


# NOTE: camera feed analyzer (cv2 + numpy) imports C-extensions that can fail
# during quick import checks (or on systems without compiled wheels). To allow
# the app to be imported and routes tested (e.g. with Postman) even when the
# native deps are missing, import the analyzer lazily inside the background
# task. If the import fails we log a warning and skip camera monitoring.

app = FastAPI(title="Event Rescue - Prototype")

# CORS for local frontend development
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000", "*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include routers
app.include_router(camera_router, prefix="/camera", tags=["camera"])

class Incident(BaseModel):
    zone: str
    type: str
    severity: float
    status: str
    lat: float | None = None
    lng: float | None = None

INCIDENTS = [
    {"zone": "A", "type": "crowd_surge", "severity": 0.8, "status": "critical"},
]


@app.get("/")
def root():
    return {"status": "ok", "message": "Event Rescue backend. See /docs for API."}


@app.get("/health")
def health():
    return {"status": "ok"}

@app.get("/api/debug/yolo")
def debug_yolo():
    """Debug endpoint to check YOLO status"""
    return {
        "yolo_loaded": yolo_model is not None,
        "yolo_type": str(type(yolo_model)) if yolo_model else None,
        "opencv_version": cv2.__version__
    }

# Authentication Endpoints
@app.post("/api/auth/signup")
async def signup(request: dict):
    """Sign up new user or admin"""
    from .services.db_service import create_user
    import secrets
    
    name = request.get("name")
    email = request.get("email")
    password = request.get("password")
    role = request.get("role", "user")  # 'user' or 'admin'
    phone = request.get("phone", "")
    
    if not all([name, email, password]):
        return {"status": "error", "message": "Name, email, and password are required"}
    
    user = create_user(name, email, password, role, phone)
    
    if user:
        # Generate a simple token (in production, use JWT)
        token = secrets.token_urlsafe(32)
        return {
            "status": "ok",
            "message": "Account created successfully",
            "token": token,
            "user": {
                "id": user["id"],
                "name": user["name"],
                "email": user["email"],
                "role": user["role"]
            }
        }
    else:
        return {"status": "error", "message": "Email already exists"}

@app.post("/api/auth/login")
async def login(request: dict):
    """Login user or admin"""
    from .services.db_service import authenticate_user
    import secrets
    
    email = request.get("email")
    password = request.get("password")
    
    if not all([email, password]):
        return {"status": "error", "message": "Email and password are required"}
    
    user = authenticate_user(email, password)
    
    if user:
        # Generate a simple token (in production, use JWT)
        token = secrets.token_urlsafe(32)
        return {
            "status": "ok",
            "message": "Login successful",
            "token": token,
            "user": user
        }
    else:
        return {"status": "error", "message": "Invalid email or password"}

@app.get("/api/auth/users")
async def list_users():
    """List all registered users (admin only in production)"""
    from .services.db_service import list_all_users
    return {"status": "ok", "users": list_all_users()}

# Participant Camera Streaming
_participant_streams: Dict[str, Dict[str, Any]] = {}  # Store latest frames from participants

@app.post("/api/participant/stream")
async def participant_stream(
    participant_id: str = Form(...),
    participant_name: str = Form(...),
    image: UploadFile = File(...)
):
    """Receive camera frame from participant"""
    try:
        # Read and encode image
        content = await image.read()
        import base64
        encoded_frame = base64.b64encode(content).decode('utf-8')
        
        # Store latest frame
        _participant_streams[participant_id] = {
            "id": participant_id,
            "name": participant_name,
            "frame": encoded_frame,
            "timestamp": datetime.now().isoformat(),
            "status": "streaming"
        }
        
        print(f"üìπ Received frame from participant: {participant_name} (ID: {participant_id})")
        return {"status": "ok", "message": "Frame received"}
    except Exception as e:
        print(f"‚ùå Error receiving participant frame: {e}")
        return {"status": "error", "message": str(e)}

@app.get("/api/participant/streams")
async def get_participant_streams():
    """Get all active participant camera streams"""
    # Remove stale streams (older than 10 seconds)
    current_time = datetime.now()
    active_streams = {}
    
    for participant_id, stream_data in _participant_streams.items():
        stream_time = datetime.fromisoformat(stream_data["timestamp"])
        age = (current_time - stream_time).total_seconds()
        
        if age < 10:  # Stream is active if updated within last 10 seconds
            active_streams[participant_id] = {
                "id": stream_data["id"],
                "name": stream_data["name"],
                "frame": stream_data["frame"],
                "timestamp": stream_data["timestamp"],
                "status": "active"
            }
        else:
            active_streams[participant_id] = {
                "id": stream_data["id"],
                "name": stream_data["name"],
                "frame": None,
                "timestamp": stream_data["timestamp"],
                "status": "inactive"
            }
    
    return {"status": "ok", "streams": list(active_streams.values())}

@app.get("/api/hello")
def api_hello():
    return {"message": "Hello from FastAPI + React!"}

@app.get("/incidents")
def get_incidents():
    # Return incidents detected via camera routes (in-memory DB)
    return {"incidents": list_incidents()}

# Update incident status (resolve)
@app.patch("/incidents/{incident_id}")
async def update_incident(incident_id: int, payload: dict):
    """Update incident status (e.g., resolve)"""
    incidents_list = list_incidents()
    
    for incident in incidents_list:
        if incident.get('id') == incident_id:
            # Update status
            incident['status'] = payload.get('status', 'resolved')
            print(f"‚úÖ Updated incident #{incident_id} status to: {incident['status']}")
            return {"status": "ok", "incident": incident}
    
    return {"status": "error", "message": f"Incident #{incident_id} not found"}

# Programmatically add incidents (for live scan matches etc.)
@app.post("/api/incidents/add")
@app.post("/incidents/add")
async def add_incident_api(payload: dict):
    inc = add_incident(payload)
    return {"status": "ok", "incident": inc}


@app.post("/dispatch")
async def dispatch_endpoint(incident: Incident):
    result = await dispatch_help(incident.dict())
    return {"message": "Dispatch initiated", "details": result}

# Voice Alert endpoint for mobile participants
@app.post("/api/voice-alert")
@app.post("/voice-alert")
async def receive_voice_alert(alert_data: dict):
    """Receive voice alerts from mobile participants."""
    print(f"üö® VOICE ALERT: {alert_data.get('type', 'unknown')} from device {alert_data.get('deviceId', 'unknown')}")
    print(f"üìç Location: {alert_data.get('location', {}).get('latitude', 0)}, {alert_data.get('location', {}).get('longitude', 0)}")
    print(f"üé§ Confidence: {alert_data.get('confidence', 0)}%")
    
    # Add to incidents list
    INCIDENTS.append({
        "zone": "Mobile Device",
        "type": f"voice_{alert_data.get('type', 'unknown')}",
        "severity": alert_data.get('confidence', 0) / 100,
        "status": "critical",
        "lat": alert_data.get('location', {}).get('latitude'),
        "lng": alert_data.get('location', {}).get('longitude')
    })
    
    # Auto-dispatch for voice alerts
    if alert_data.get('confidence', 0) > 70:
        await dispatch_help({
            "type": f"voice_{alert_data.get('type', 'unknown')}",
            "zone": "Mobile Device",
            "severity": alert_data.get('confidence', 0) / 100,
            "location": alert_data.get('location', {}),
            "deviceId": alert_data.get('deviceId')
        })
    
    return {"status": "received", "alert_id": alert_data.get('id')}

# Lost & Found endpoints
@app.post("/api/lostfound/report")
@app.post("/lostfound/report")
async def lostfound_report(
    reporter: str = Form(...),
    description: str = Form(""),
    image: UploadFile = File(...)
):
    # For demo: we don't persist the actual file to disk; store metadata only
    # Read image bytes and compute a compact color histogram for matching
    content = await image.read()
    np_arr = np.frombuffer(content, np.uint8)
    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
    hist_vec = None
    if img is not None:
        img_small = cv2.resize(img, (64, 64))
        # HSV histogram (H and S channels) flattened
        hsv = cv2.cvtColor(img_small, cv2.COLOR_BGR2HSV)
        h_hist = cv2.calcHist([hsv], [0], None, [32], [0, 180])
        s_hist = cv2.calcHist([hsv], [1], None, [32], [0, 256])
        hist = np.concatenate([h_hist.flatten(), s_hist.flatten()]).astype(float)
        hist /= (hist.sum() + 1e-6)
        hist_vec = hist.tolist()

    item = add_lost_found({
        "reporter": reporter,
        "description": description,
        "filename": image.filename,
        "status": "reported",
        "hist": hist_vec,
    })
    # Create an incident for authority visibility
    add_incident({
        "zone": "Lost&Found",
        "type": "lost_person_report",
        "severity": 0.6,
        "status": "active",
    })
    return {"status": "ok", "item": item}

@app.get("/api/lostfound")
@app.get("/lostfound")
async def lostfound_list():
    return {"items": list_lost_found()}

@app.delete("/api/lostfound/{report_id}")
@app.delete("/lostfound/{report_id}")
async def lostfound_delete(report_id: str):
    """Delete a lost & found report by ID"""
    from .services.db_service import delete_lost_found
    success = delete_lost_found(report_id)
    if success:
        return {"status": "ok", "message": "Report deleted successfully"}
    return {"status": "error", "message": "Report not found"}

@app.post("/api/lostfound/match")
@app.post("/lostfound/match")
async def lostfound_match(image: UploadFile = File(...)):
    content = await image.read()
    np_arr = np.frombuffer(content, np.uint8)
    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
    if img is None:
        return {"matches": []}
    img_small = cv2.resize(img, (64, 64))
    hsv = cv2.cvtColor(img_small, cv2.COLOR_BGR2HSV)
    h_hist = cv2.calcHist([hsv], [0], None, [32], [0, 180])
    s_hist = cv2.calcHist([hsv], [1], None, [32], [0, 256])
    hist = np.concatenate([h_hist.flatten(), s_hist.flatten()]).astype(float)
    hist /= (hist.sum() + 1e-6)

    # naive cosine similarity against stored items that have hist
    items = list_lost_found()
    sims = []
    for it in items:
        ref = it.get("hist")
        if not ref:
            continue
        ref = np.array(ref, dtype=float)
        sim = float(np.dot(hist, ref) / (np.linalg.norm(hist) * np.linalg.norm(ref) + 1e-6))
        sims.append({"item": it, "similarity": sim})
    sims.sort(key=lambda x: x["similarity"], reverse=True)
    top = sims[:3]
    return {
        "matches": [
            {"id": t["item"]["id"], "reporter": t["item"].get("reporter"), "description": t["item"].get("description"), "score": t["similarity"]}
            for t in top
        ]
    }

# Participant join endpoint (notify authorities that a participant connected)
@app.post("/api/participant/join")
@app.post("/participant/join")
async def participant_join(join: dict):
    device_id = (join or {}).get("deviceId", "unknown")
    loc = (join or {}).get("location") or {}
    add_incident({
        "zone": "Participants",
        "type": "participant_joined",
        "severity": 0.1,
        "status": "info",
        "deviceId": device_id,
        "lat": loc.get("latitude"),
        "lng": loc.get("longitude"),
    })
    return {"status": "ok"}

@app.get("/api/participants")
@app.get("/participants")
async def list_participants():
    """List all connected participants"""
    try:
        incidents = list_incidents()
        participants = [inc for inc in incidents if inc.get("type") == "participant_joined"]
        return {"status": "ok", "participants": participants}
    except Exception as e:
        return {"status": "error", "message": f"Failed to list participants: {e}"}

# Enhanced NLP summary using Perplexity AI
@app.get("/api/nlp/summary")
@app.get("/nlp/summary")
async def nlp_summary():
    incs = list_incidents()[-10:]
    if not incs:
        return {"summary": "No incidents yet. Monitoring active."}
    
    # Prepare context for AI
    context = {
        "incidents": incs,
        "timestamp": incs[-1].get("timestamp") if incs else None,
        "total_incidents": len(incs)
    }
    
    try:
        # Use Perplexity AI for intelligent summarization
        summary = await generate_perplexity_summary(context)
        return {"summary": summary}
    except Exception as e:
        print(f"Perplexity AI summary failed: {e}")
        # Fallback to simple summary
        kinds = {}
        for i in incs:
            kinds[i.get("type", "unknown")] = kinds.get(i.get("type", "unknown"), 0) + 1
        top = sorted(kinds.items(), key=lambda x: x[1], reverse=True)
        s = ", ".join([f"{k} x{v}" for k, v in top])
        return {"summary": f"Recent activity: {s}. Stay vigilant and monitor critical zones."}

# AI-powered question answering with live camera analysis
@app.post("/api/nlp/ask")
@app.post("/nlp/ask")
async def ask_question(question_data: dict):
    question = question_data.get("question", "")
    if not question:
        return {"answer": "Please provide a question."}
    
    # Get current context
    incs = list_incidents()[-10:]
    lf_items = list_lost_found()[-5:]
    
    # Analyze live camera data if available
    live_camera_analysis = await analyze_live_camera_data()
    
    context = {
        "question": question,
        "incidents": incs,
        "lost_found_items": lf_items,
        "live_camera_analysis": live_camera_analysis,
        "timestamp": incs[-1].get("timestamp") if incs else None
    }
    
    try:
        answer = await generate_ai_answer(context)
        return {"answer": answer}
    except Exception as e:
        print(f"AI answer failed: {e}")
        return {"answer": "Unable to process question at this time. Please try again."}

# Live camera analysis endpoint
@app.post("/api/camera/analyze")
@app.post("/camera/analyze")
async def analyze_camera_frame(image: UploadFile = File(...)):
    """Analyze a live camera frame for AI insights"""
    try:
        contents = await image.read()
        nparr = np.frombuffer(contents, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if frame is None:
            raise ValueError("Could not decode image")
        
        # Perform comprehensive analysis
        analysis = await analyze_frame_content(frame)
        
        # Auto-create incidents ONLY for fire detection (missing person has its own logic)
        # Note: Don't create incidents for suspicious_activity to avoid spam
        if analysis.get("fire_detected"):
            # Check if fire incident already exists
            existing_fire = any(
                inc.get('type') == 'fire_detected' and inc.get('status') != 'resolved'
                for inc in list_incidents()['incidents']
            )
            
            if not existing_fire:
                add_incident({
                    "type": "fire_detected",
                    "zone": "Live Camera",
                    "severity": 0.9,
                    "confidence": 85,
                    "timestamp": datetime.now().isoformat(),
                    "description": "üî• Fire detected in camera feed",
                    "source": "live_camera_analysis",
                    "status": "active"
                })
                print("üî• Created fire detection incident")
        
        return {"status": "ok", "analysis": analysis}
    except Exception as e:
        return {"status": "error", "message": f"Analysis failed: {e}"}

# Perplexity AI integration functions
async def generate_perplexity_summary(context):
    """Generate AI summary using Perplexity AI API"""
    incidents_text = "\n".join([
        f"- {inc.get('type', 'unknown')} in {inc.get('zone', 'unknown')} at {inc.get('timestamp', 'unknown')} (severity: {inc.get('severity', 0)})"
        for inc in context["incidents"]
    ])
    
    prompt = f"""
    You are an AI security analyst for an event management system. 
    Analyze these recent incidents and provide a concise, actionable summary:
    
    Incidents:
    {incidents_text}
    
    Total incidents: {context["total_incidents"]}
    
    Provide:
    1. Key patterns or trends
    2. Risk assessment
    3. Recommended actions
    4. Areas requiring attention
    
    Keep it under 200 words and professional.
    """
    
    try:
        # Use Perplexity AI API (replace with actual API key)
        import httpx
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.perplexity.ai/chat/completions",
                # api key = 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
                headers={
                    "Authorization": f"Bearer {os.getenv('PERPLEXITY_API_KEY', 'api key')}",  # Replace with actual key
                    "Content-Type": "application/json"
                },
                json={
                    "model": "llama-3.1-sonar-small-128k-online",
                    "messages": [
                        {"role": "system", "content": "You are an expert security analyst for event management systems."},
                        {"role": "user", "content": prompt}
                    ],
                    "max_tokens": 300,
                    "temperature": 0.3
                },
                timeout=10.0
            )
            
            if response.status_code == 200:
                data = response.json()
                return data["choices"][0]["message"]["content"]
            else:
                print(f"Perplexity API error: {response.status_code}")
                return await simulate_ai_summary(prompt)
    except Exception as e:
        print(f"Perplexity API failed: {e}")
        return await simulate_ai_summary(prompt)

async def simulate_ai_summary(prompt):
    """Fallback AI summary simulation"""
    import asyncio
    await asyncio.sleep(0.3)
    
    if "fire" in prompt.lower():
        return "üö® CRITICAL ALERT: Fire incidents detected in multiple zones. Immediate evacuation protocols activated. Fire department dispatched. Monitor all areas for smoke/fire spread. Ensure clear evacuation routes."
    elif "crowd" in prompt.lower():
        return "‚ö†Ô∏è HIGH RISK: Crowd surge patterns detected. Deploy additional security personnel to congested areas. Monitor crowd density and flow patterns. Prepare crowd control measures."
    elif "voice" in prompt.lower():
        return "üì¢ ALERT: Multiple voice distress calls received. Security teams dispatched to reported locations. Verify caller locations and provide immediate assistance."
    else:
        return "üìä STATUS: System monitoring active. Recent incidents show normal event patterns. Continue vigilant monitoring. All systems operational."

async def generate_ai_answer(context):
    """Generate AI answer using Puter AI with live camera data"""
    incidents_text = "\n".join([
        f"- {inc.get('type', 'unknown')} in {inc.get('zone', 'unknown')} at {inc.get('timestamp', 'unknown')}"
        for inc in context["incidents"][-5:]
    ])
    
    lf_text = "\n".join([
        f"- {item.get('description', 'No description')} reported by {item.get('reporter', 'Unknown')}"
        for item in context["lost_found_items"]
    ])
    
    # Include live camera analysis
    camera_text = ""
    if context.get("live_camera_analysis"):
        analysis = context["live_camera_analysis"]
        camera_text = f"""
Live Camera Analysis:
- Crowd Density: {analysis.get('crowd_density', 'Unknown')}
- Fire/Smoke Detection: {analysis.get('fire_detected', False)}
- Panic Detection: {analysis.get('panic_detected', False)}
- People Count: {analysis.get('people_count', 'Unknown')}
- Activity Level: {analysis.get('activity_level', 'Unknown')}
- Safety Score: {analysis.get('safety_score', 'Unknown')}/10
"""
    
    prompt = f"""
    You are an AI assistant for an event security system. Answer this question based on current data including live camera analysis:
    
    Question: {context["question"]}
    
    Recent Incidents:
    {incidents_text}
    
    Lost & Found Reports:
    {lf_text}
    
    {camera_text}
    
    Provide a helpful, accurate answer based on the available data including live camera insights. If the question cannot be answered with current data, say so.
    """
    
    return await simulate_puter_ai(prompt)

# Live camera analysis functions
async def analyze_live_camera_data():
    """Analyze live camera data for AI context"""
    try:
        # This would connect to active camera feeds
        # For now, return mock analysis based on recent incidents
        incs = list_incidents()[-5:]
        
        # Simulate camera analysis based on incidents
        fire_detected = any(inc.get('type') in ['fire_detected', 'smoke_detected'] for inc in incs)
        crowd_surge = any(inc.get('type') == 'crowd_surge' for inc in incs)
        panic_detected = any(inc.get('type') == 'panic_detected' for inc in incs)
        
        # Calculate safety score based on incidents
        safety_score = 10
        for inc in incs:
            severity = inc.get('severity', 0)
            safety_score -= severity * 2
        
        return {
            "crowd_density": "High" if crowd_surge else "Normal",
            "fire_detected": fire_detected,
            "panic_detected": panic_detected,
            "people_count": "50-100" if crowd_surge else "20-50",
            "activity_level": "High" if len(incs) > 3 else "Normal",
            "safety_score": max(0, min(10, safety_score))
        }
    except Exception as e:
        print(f"Camera analysis failed: {e}")
        return {
            "crowd_density": "Unknown",
            "fire_detected": False,
            "panic_detected": False,
            "people_count": "Unknown",
            "activity_level": "Unknown",
            "safety_score": 5
        }

# Load YOLO model once at startup for person detection
print("üîÑ Loading YOLO model...", flush=True)
try:
    from ultralytics import YOLO
    yolo_model = YOLO('yolov8n.pt')  # Nano model for speed
    print("‚úÖ YOLO model loaded successfully!", flush=True)
    print(f"YOLO model type: {type(yolo_model)}", flush=True)
except Exception as e:
    print(f"‚ö†Ô∏è YOLO model not available: {e}", flush=True)
    import traceback
    traceback.print_exc()
    yolo_model = None
    print("‚ö†Ô∏è Falling back to contour-based detection", flush=True)

async def analyze_frame_content(frame):
    """Enhanced camera frame analysis with YOLO person detection and missing person matching"""
    try:
        # Check if frame is too dark or invalid
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        mean_brightness = np.mean(gray)
        
        # Enhanced dark detection - check for completely black frames (camera blocked)
        if mean_brightness < 5:
            return {
                "fire_detected": False,
                "smoke_detected": False,
                "crowd_density": "Unknown - Camera Blocked",
                "people_count": 0,
                "activity_level": "Unknown - Camera Blocked",
                "safety_score": 3,
                "camera_status": "blocked",
                "brightness": mean_brightness,
                "missing_person_detected": False,
                "suspicious_activity": False,
                "description": "üö´ Camera appears to be blocked or covered",
                "analysis_timestamp": datetime.now().isoformat(),
                "bounding_boxes": [],
                "matched_persons": []
            }
        
        # If frame is too dark (mean brightness < 30), return dark frame analysis
        if mean_brightness < 30:
            return {
                "fire_detected": False,
                "smoke_detected": False,
                "crowd_density": "Unknown - Camera Dark",
                "people_count": 0,
                "activity_level": "Unknown - Camera Dark",
                "safety_score": 5,
                "camera_status": "dark",
                "brightness": mean_brightness,
                "missing_person_detected": False,
                "suspicious_activity": False,
                "description": "‚ö†Ô∏è Camera feed too dark for analysis",
                "analysis_timestamp": datetime.now().isoformat(),
                "bounding_boxes": [],
                "matched_persons": []
            }
        
        # Convert to HSV for better analysis
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        
        # Basic analysis
        height, width = frame.shape[:2]
        total_pixels = height * width
        
        # STRICT Fire detection - Only detect ACTUAL fire (bright red/orange/yellow)
        # Fire must be:
        # 1. Red/Orange/Yellow color
        # 2. HIGH saturation (bright, vivid color - not dull red objects)
        # 3. HIGH brightness (fire is bright!)
        
        # Range 1: Bright RED fire
        fire_lower1 = np.array([0, 120, 180])    # Hue: 0-10 (red), Saturation: >120 (vivid), Value: >180 (bright)
        fire_upper1 = np.array([10, 255, 255])
        fire_mask1 = cv2.inRange(hsv, fire_lower1, fire_upper1)
        
        # Range 2: Bright ORANGE fire
        fire_lower2 = np.array([10, 120, 180])   # Hue: 10-25 (orange), Saturation: >120, Value: >180
        fire_upper2 = np.array([25, 255, 255])
        fire_mask2 = cv2.inRange(hsv, fire_lower2, fire_upper2)
        
        # Range 3: Bright YELLOW fire (flames tip)
        fire_lower3 = np.array([25, 100, 200])   # Hue: 25-35 (yellow), Saturation: >100, Value: >200 (very bright)
        fire_upper3 = np.array([35, 255, 255])
        fire_mask3 = cv2.inRange(hsv, fire_lower3, fire_upper3)
        
        # Combine all fire color ranges
        fire_mask = cv2.bitwise_or(fire_mask1, fire_mask2)
        fire_mask = cv2.bitwise_or(fire_mask, fire_mask3)
        
        fire_pixels = cv2.countNonZero(fire_mask)
        fire_ratio = fire_pixels / total_pixels
        
        # Enhanced Smoke detection
        # Convert to LAB color space for better smoke detection
        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
        smoke_mask = cv2.inRange(lab, np.array([0, 0, 0]), np.array([255, 255, 200]))
        smoke_pixels = cv2.countNonZero(smoke_mask)
        smoke_ratio = smoke_pixels / total_pixels
        
        # Compute edges for crowd density calculation (needed for all paths)
        edges = cv2.Canny(gray, 50, 150)
        
        # YOLO-based person detection with bounding boxes
        people_count = 0
        bounding_boxes = []
        detected_persons = []
        
        if yolo_model:
            try:
                results = yolo_model(frame, verbose=False)
                for result in results:
                    boxes = result.boxes
                    for box in boxes:
                        cls = int(box.cls[0])
                        conf = float(box.conf[0])
                        # Class 0 is 'person' in COCO dataset
                        if cls == 0 and conf > 0.3:  # 30% confidence threshold
                            people_count += 1
                            # Get bounding box coordinates
                            x1, y1, x2, y2 = box.xyxy[0].tolist()
                            bounding_boxes.append({
                                "x1": int(x1), "y1": int(y1),
                                "x2": int(x2), "y2": int(y2),
                                "confidence": round(conf * 100, 1)
                            })
                            # Extract person crop for matching
                            person_crop = frame[int(y1):int(y2), int(x1):int(x2)]
                            if person_crop.size > 0:
                                detected_persons.append(person_crop)
                print(f"‚úÖ YOLO detected {people_count} people with {len(bounding_boxes)} bounding boxes")
            except Exception as e:
                print(f"YOLO detection failed: {e}")
                # Fallback to contour detection
                contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                for contour in contours:
                    area = cv2.contourArea(contour)
                    if area > 1000:
                        x, y, w, h = cv2.boundingRect(contour)
                        aspect_ratio = h / w if w > 0 else 0
                        if 1.5 < aspect_ratio < 4.0:
                            people_count += 1
                            bounding_boxes.append({
                                "x1": x, "y1": y, "x2": x + w, "y2": y + h,
                                "confidence": 75.0
                            })
        else:
            # Fallback: contour-based detection
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 1000:
                    x, y, w, h = cv2.boundingRect(contour)
                    aspect_ratio = h / w if w > 0 else 0
                    if 1.5 < aspect_ratio < 4.0:
                        people_count += 1
                        bounding_boxes.append({
                            "x1": x, "y1": y, "x2": x + w, "y2": y + h,
                            "confidence": 75.0
                        })
        
        # Missing person detection - compare detected persons against lost & found database
        missing_person_detected = False
        matched_persons = []
        lf_items = list_lost_found()
        
        if lf_items and detected_persons:
            print(f"üîç Checking {len(detected_persons)} detected persons against {len(lf_items)} reports...")
            for idx, person_crop in enumerate(detected_persons):
                try:
                    print(f"  Analyzing person {idx + 1}/{len(detected_persons)}...")
                    # Resize and compute histogram for comparison
                    img_small = cv2.resize(person_crop, (64, 64))
                    hsv_crop = cv2.cvtColor(img_small, cv2.COLOR_BGR2HSV)
                    h_hist = cv2.calcHist([hsv_crop], [0], None, [32], [0, 180])
                    s_hist = cv2.calcHist([hsv_crop], [1], None, [32], [0, 256])
                    hist = np.concatenate([h_hist.flatten(), s_hist.flatten()]).astype(float)
                    hist /= (hist.sum() + 1e-6)
                    
                    # Compare against all reported missing persons
                    for item in lf_items:
                        if item.get('status') != 'reported':
                            continue
                        ref_hist = item.get('hist')
                        if not ref_hist:
                            continue
                        ref_hist = np.array(ref_hist, dtype=float)
                        # Cosine similarity
                        similarity = float(np.dot(hist, ref_hist) / (np.linalg.norm(hist) * np.linalg.norm(ref_hist) + 1e-6))
                        
                        print(f"  Comparing with report #{item.get('id')}: similarity = {round(similarity * 100, 1)}% (threshold: 85%)")
                        
                        # STRICT MATCHING: 85% similarity required to avoid false positives!
                        if similarity > 0.85:  # 85% similarity - very strict to match only the specific person
                            missing_person_detected = True
                            matched_persons.append({
                                "id": item.get('id'),
                                "reporter": item.get('reporter'),
                                "description": item.get('description'),
                                "similarity": round(similarity * 100, 1)
                            })
                            print(f"‚úÖ STRONG MATCH FOUND! Report #{item.get('id')}: {item.get('description')} - Similarity: {round(similarity * 100, 1)}%")
                            
                            # ONLY create incident if one doesn't already exist for this report
                            existing_incidents_response = list_incidents()
                            existing_incidents = existing_incidents_response.get('incidents', [])
                            report_id = item.get('id')
                            
                            # Check if alert already exists for this report (not resolved)
                            already_alerted = any(
                                inc.get('matched_report_id') == report_id 
                                and inc.get('status') != 'resolved'
                                for inc in existing_incidents
                            )
                            
                            print(f"  üîç Checking duplicates: report_id={report_id}, existing_incidents={len(existing_incidents)}, already_alerted={already_alerted}")
                            
                            # Debug: Show all matching incidents
                            for inc in existing_incidents:
                                if inc.get('matched_report_id') == report_id:
                                    print(f"    Found incident #{inc.get('id')}: matched_report_id={inc.get('matched_report_id')}, status={inc.get('status', 'NO STATUS')}")
                            
                            if not already_alerted:
                                # Create alert ONLY ONCE
                                new_incident = add_incident({
                                    "type": "missing_person_found",
                                    "zone": "Live Camera",
                                    "severity": 0.9,
                                    "confidence": round(similarity * 100, 1),
                                    "timestamp": datetime.now().isoformat(),
                                    "description": f"üîç MATCH FOUND: {item.get('description', 'Missing person')} - Similarity: {round(similarity * 100, 1)}%",
                                    "source": "live_camera_matching",
                                    "matched_report_id": report_id,
                                    "status": "active"  # Keep active until report deleted
                                })
                                print(f"‚úÖ Created NEW alert #{new_incident.get('id')} for report #{report_id}")
                            else:
                                print(f"‚è≠Ô∏è Alert already exists for report #{report_id}, skipping duplicate")
                            
                            break  # Stop after first match
                        elif similarity > 0.70:
                            print(f"  ‚ö†Ô∏è Weak match (similarity: {round(similarity * 100, 1)}%) - Not strong enough, skipping")
                except Exception as e:
                    print(f"Person matching error: {e}")
                    continue
        
        # Calculate fire/smoke metrics FIRST (before using them)
        # STRICT fire detection: Requires 5% of frame to be bright fire colors
        fire_detected = fire_ratio > 0.05  # At least 5% of pixels must be BRIGHT fire colors
        smoke_detected = smoke_ratio > 0.15  # Smoke threshold unchanged
        
        # Suspicious activity detection
        suspicious_activity = False
        if fire_ratio > 0.05 or smoke_ratio > 0.2 or people_count > 10:
            suspicious_activity = True
        
        # Crowd density calculation
        edge_pixels = cv2.countNonZero(edges)
        edge_ratio = edge_pixels / total_pixels
        crowd_density = "High" if edge_ratio > 0.15 else "Normal" if edge_ratio > 0.08 else "Low"
        
        # Generate description
        description_parts = []
        if fire_detected:
            description_parts.append("üî• Fire detected in camera view")
        if smoke_detected:
            description_parts.append("üí® Smoke detected in camera view")
        if people_count > 0:
            description_parts.append(f"üë• {people_count} people detected")
        if missing_person_detected:
            description_parts.append("üîç Potential missing person match")
        if suspicious_activity:
            description_parts.append("‚ö†Ô∏è Suspicious activity detected")
        
        description = "; ".join(description_parts) if description_parts else "Normal activity detected"
        
        print(f"üìä Analysis: people={people_count}, fire={fire_detected}, smoke={smoke_detected}, missing_match={missing_person_detected}, boxes={len(bounding_boxes)}")
        
        # Safety score calculation
        safety_score = 10
        if fire_detected: safety_score -= 5
        if smoke_detected: safety_score -= 3
        if missing_person_detected: safety_score -= 2
        if suspicious_activity: safety_score -= 1
        
        return {
            "fire_detected": fire_detected,
            "smoke_detected": smoke_detected,
            "crowd_density": crowd_density,
            "people_count": people_count,
            "activity_level": "High" if edge_ratio > 0.12 else "Normal",
            "safety_score": max(0, min(10, safety_score)),
            "camera_status": "active",
            "brightness": mean_brightness,
            "missing_person_detected": missing_person_detected,
            "suspicious_activity": suspicious_activity,
            "description": description,
            "analysis_timestamp": datetime.now().isoformat(),
            "bounding_boxes": bounding_boxes,
            "matched_persons": matched_persons
        }
        print(f"‚úÖ Returning analysis: {people_count} people, {len(bounding_boxes)} boxes, {len(matched_persons)} matches")
    except Exception as e:
        print(f"Frame analysis failed: {e}")
        import traceback
        traceback.print_exc()
        return {
            "fire_detected": False,
            "smoke_detected": False,
            "crowd_density": "Unknown - Analysis Failed",
            "people_count": 0,
            "activity_level": "Unknown - Analysis Failed",
            "safety_score": 5,
            "camera_status": "error",
            "brightness": 0,
            "missing_person_detected": False,
            "suspicious_activity": False,
            "description": f"Analysis failed: {str(e)}",
            "analysis_timestamp": datetime.now().isoformat(),
            "bounding_boxes": [],
            "matched_persons": []
        }

async def simulate_puter_ai(prompt):
    """Enhanced AI response with camera status awareness"""
    import asyncio
    await asyncio.sleep(0.5)  # Simulate API delay
    
    # Check for camera status indicators in prompt
    camera_dark = "camera dark" in prompt.lower() or "dark" in prompt.lower()
    camera_blocked = "camera blocked" in prompt.lower() or "blocked" in prompt.lower()
    camera_error = "analysis failed" in prompt.lower() or "error" in prompt.lower()
    
    # Enhanced responses with camera data
    if "summary" in prompt.lower():
        if camera_blocked:
            return "üö´ CAMERA BLOCKED: Camera appears to be covered or blocked. Please check:\n‚Ä¢ Remove any covers or obstructions\n‚Ä¢ Ensure camera lens is clear\n‚Ä¢ Check camera positioning\n‚Ä¢ Restart camera if needed"
        elif camera_dark:
            return "‚ö†Ô∏è CAMERA ALERT: Camera feed is too dark for proper analysis. Please check lighting conditions or camera positioning. Unable to detect fire, smoke, or crowd activity."
        elif camera_error:
            return "‚ùå CAMERA ERROR: Unable to analyze camera feed. Please check camera connection and try again."
        elif "fire" in prompt.lower() or "fire_detected" in prompt.lower():
            return "üö® CRITICAL: Fire incidents detected in live camera feed. Immediate evacuation protocols activated. Fire department dispatched. Monitor all zones for smoke/fire spread. Ensure clear evacuation routes."
        elif "crowd" in prompt.lower() or "crowd_density" in prompt.lower():
            return "‚ö†Ô∏è HIGH RISK: Crowd surge patterns detected in live video. Deploy additional security personnel to congested areas. Monitor crowd density and flow patterns. Prepare crowd control measures."
        elif "voice" in prompt.lower():
            return "üì¢ ALERT: Multiple voice distress calls received. Security teams dispatched to reported locations. Verify caller locations and provide immediate assistance."
        else:
            return "üìä STATUS: System monitoring active with live camera analysis. Recent incidents show normal event patterns. Continue vigilant monitoring. All systems operational."
    else:
        # Enhanced question answering with camera data
        if camera_blocked:
            return "üö´ CAMERA BLOCKED: Your camera appears to be covered or blocked (brightness: very low). I cannot analyze the scene. Please:\n‚Ä¢ Remove any covers or obstructions\n‚Ä¢ Ensure camera lens is clear\n‚Ä¢ Check camera positioning\n‚Ä¢ Restart camera if needed"
        elif camera_dark:
            return "‚ö†Ô∏è CAMERA ISSUE: Your camera feed is too dark for analysis. I cannot detect fire, smoke, or crowd activity. Please:\n‚Ä¢ Check if your camera is covered or blocked\n‚Ä¢ Ensure adequate lighting\n‚Ä¢ Try adjusting camera settings\n‚Ä¢ Restart the camera feed"
        elif camera_error:
            return "‚ùå CAMERA ERROR: Unable to analyze your camera feed. Please check:\n‚Ä¢ Camera permissions\n‚Ä¢ Camera connection\n‚Ä¢ Try refreshing the page\n‚Ä¢ Contact support if issue persists"
        elif "missing" in prompt.lower() or "person" in prompt.lower():
            if "missing_person_detected" in prompt.lower() and "true" in prompt.lower():
                return "üîç MISSING PERSON DETECTED: Live camera analysis shows potential match with reported missing person! Immediate action required:\n‚Ä¢ Verify identity with authorities\n‚Ä¢ Contact family/guardians\n‚Ä¢ Secure the area\n‚Ä¢ Document the encounter"
            else:
                # Get lost & found count from database
                lf_items = list_lost_found()
                lf_count = len([item for item in lf_items if item.get('status') == 'reported'])
                return f"üîç MISSING PERSON STATUS: Currently {lf_count} missing person reports active. Live camera analysis is continuously monitoring for matches. Use Live Scan feature to check current view against reported missing persons."
        elif "fire" in prompt.lower():
            if "fire_detected" in prompt.lower() and "true" in prompt.lower():
                return "üö® FIRE DETECTED: Live camera analysis shows fire in the area! Immediate action required:\n‚Ä¢ Evacuate the area immediately\n‚Ä¢ Call emergency services\n‚Ä¢ Alert authorities\n‚Ä¢ Follow evacuation protocols"
            else:
                return "‚úÖ FIRE STATUS: No fire detected in live camera analysis. Fire detection systems are operational and monitoring the area continuously."
        elif "crowd" in prompt.lower():
            return "üë• CROWD ANALYSIS: Live camera shows current crowd density levels. Security teams are positioned based on real-time video analysis. Crowd flow patterns are being monitored continuously."
        elif "lost" in prompt.lower():
            return "üîç LOST & FOUND: Active reports available. Use Live Scan feature to match people with reported items using real-time camera analysis."
        elif "safety" in prompt.lower():
            return "üõ°Ô∏è SAFETY STATUS: Live camera analysis provides real-time safety monitoring. The system continuously analyzes crowd density, fire/smoke detection, and activity levels to ensure event safety."
        else:
            return "ü§ñ AI ASSISTANT: I can help answer questions about fire safety, crowd management, lost & found, voice alerts, and general event security using live camera analysis. What specific information do you need?"


# # üîÅ Camera Feed Background Task
# async def monitor_camera():
#     try:
#         # lazy import to avoid importing cv2/numpy at module import time
#         from app.camera_feed_analyzer import analyze_feed
#     except Exception as e:
#         print(f"‚ö†Ô∏è Camera analyzer not available, skipping monitoring: {e}")
#         return

#     async for event in analyze_feed(0, zone="A"):  # 0 = webcam; replace with RTSP/URL for CCTV
#         print(f"üì° Detected anomaly: {event}")
#         INCIDENTS.append({
#             "zone": event["zone"],
#             "type": event["type"],
#             "severity": event["severity"],
#             "status": "critical"
#         })
#         # Auto-dispatch critical incidents
#         if event["severity"] > 0.7:
#             await dispatch_help(event)


# @app.on_event("startup")
# async def start_background_tasks():
#     asyncio.create_task(monitor_camera())
#     print("üöÄ Camera monitoring task started.")


# # Path to the built frontend files
# frontend_dir = os.path.join(os.path.dirname(__file__), "frontend")

# # Serve static files
# if os.path.exists(frontend_dir):
#     app.mount("/static", StaticFiles(directory=os.path.join(frontend_dir, "assets")), name="static")

# # API routes
# @app.get("/api/hello")
# def read_root():
#     return {"message": "Hello from FastAPI + React!"}

# # Serve React index.html for all other routes
# @app.get("/{full_path:path}")
# async def serve_frontend(full_path: str):
#     index_path = os.path.join(frontend_dir, "index.html")
#     if os.path.exists(index_path):
#         return FileResponse(index_path)
#     return {"error": "Frontend not built yet"}

# Remove duplicate app definition and legacy routes below. Frontend mounting handled elsewhere.